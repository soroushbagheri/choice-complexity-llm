{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Decision-Theoretic Choice Complexity in LLMs\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/soroushbagheri/choice-complexity-llm/blob/main/notebooks/demo_colab.ipynb)\n",
        "\n",
        "This notebook demonstrates the **Choice Complexity Index (CCI)** and **Internal LLM Decision Complexity (ILDC)** framework for regulating choice complexity in language models.\n",
        "\n",
        "## What You'll Learn\n",
        "1. How to measure external choice complexity (CCI)\n",
        "2. How to detect internal decision difficulty in LLMs (ILDC)\n",
        "3. How to apply controller strategies to reduce cognitive load\n",
        "4. Visualize the results and understand the framework\n",
        "\n",
        "**Authors:** Soroush Bagheri\n",
        "**Date:** January 2026"
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“¦ Setup: Install Dependencies and Clone Repository"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/soroushbagheri/choice-complexity-llm.git\n",
        "%cd choice-complexity-llm\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q numpy pandas scipy scikit-learn matplotlib seaborn tqdm pyyaml\n",
        "\n",
        "print('âœ… Setup complete!')"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŽ¯ Quick Demo: Run Complete Framework\n",
        "\n",
        "This cell runs the full demonstration with synthetic data. No API keys needed!"
      ],
      "metadata": {
        "id": "quick_demo_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the demo with default settings\n",
        "!python experiments/demo_with_results.py --n-samples 50 --seed 42 --output results/colab_demo\n",
        "\n",
        "print('\\nâœ… Demo complete! Results saved to results/colab_demo/')"
      ],
      "metadata": {
        "id": "run_demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“Š View Results Summary"
      ],
      "metadata": {
        "id": "results_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load summary results\n",
        "with open('results/colab_demo/summary.json', 'r') as f:\n",
        "    summary = json.load(f)\n",
        "\n",
        "print('='*80)\n",
        "print('SUMMARY BY CONTROLLER STRATEGY')\n",
        "print('='*80)\n",
        "\n",
        "# Display metrics by strategy\n",
        "for strategy, metrics in summary['summary_by_strategy'].items():\n",
        "    if 'accuracy' in str(metrics):\n",
        "        print(f'\\n{strategy.upper()}:')\n",
        "        print(f\"  Mean Accuracy: {metrics.get('accuracy', {}).get('mean', 'N/A')}\")\n",
        "        print(f\"  Mean Volatility: {metrics.get('volatility_final', {}).get('mean', 'N/A')}\")\n",
        "        print(f\"  Mean CCI: {metrics.get('cci_score', {}).get('mean', 'N/A')}\")\n",
        "        print(f\"  Mean Options Shown: {metrics.get('n_options_shown', {}).get('mean', 'N/A')}\")\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('KEY CORRELATIONS')\n",
        "print('='*80)\n",
        "for corr_name, corr_value in summary['correlations'].items():\n",
        "    print(f'{corr_name}: {corr_value:.3f}')"
      ],
      "metadata": {
        "id": "view_summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“ˆ Visualize Results"
      ],
      "metadata": {
        "id": "viz_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "# Display all generated plots\n",
        "plots_dir = 'results/colab_demo/plots'\n",
        "plot_files = sorted([f for f in os.listdir(plots_dir) if f.endswith('.png')])\n",
        "\n",
        "for plot_file in plot_files:\n",
        "    print(f'\\n{\"=\"*80}')\n",
        "    print(f'{plot_file.replace(\"_\", \" \").replace(\".png\", \"\").upper()}')\n",
        "    print('='*80)\n",
        "    display(Image(filename=f'{plots_dir}/{plot_file}'))"
      ],
      "metadata": {
        "id": "display_plots"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”¬ Interactive Analysis: Explore the Data"
      ],
      "metadata": {
        "id": "analysis_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load detailed results\n",
        "results_df = pd.read_csv('results/colab_demo/demo_results.csv')\n",
        "\n",
        "print('Dataset Shape:', results_df.shape)\n",
        "print('\\nFirst few rows:')\n",
        "results_df.head()"
      ],
      "metadata": {
        "id": "load_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical summary\n",
        "print('Statistical Summary by Controller Strategy:\\n')\n",
        "results_df.groupby('controller_strategy')[['accuracy', 'cci_score', 'ildc_score', 'volatility_final']].describe().round(3)"
      ],
      "metadata": {
        "id": "stats_summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§ª Custom Experiment: Try Your Own Parameters\n",
        "\n",
        "Modify the parameters below to run custom experiments!"
      ],
      "metadata": {
        "id": "custom_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/choice-complexity-llm')\n",
        "\n",
        "from src.datasets import SyntheticChoiceDataset\n",
        "from src.cci import ChoiceComplexityIndex\n",
        "import numpy as np\n",
        "\n",
        "# Create a custom choice problem\n",
        "dataset_gen = SyntheticChoiceDataset(seed=42)\n",
        "cci_calc = ChoiceComplexityIndex()\n",
        "\n",
        "# Generate one sample\n",
        "sample = dataset_gen.generate_dataset(n_samples=1)[0]\n",
        "\n",
        "print('='*80)\n",
        "print('SAMPLE CHOICE PROBLEM')\n",
        "print('='*80)\n",
        "print(f'Number of options: {len(sample[\"options\"])}')\n",
        "print(f'Ground truth choice: {sample[\"ground_truth_choice\"]}\\n')\n",
        "\n",
        "# Show first 3 options\n",
        "for i, option in enumerate(sample['options'][:3]):\n",
        "    print(f'Option {i}:')\n",
        "    print(f'  Attributes: {option[\"attributes\"]}')\n",
        "    if len(sample['options']) > 3 and i == 2:\n",
        "        print(f'\\n... and {len(sample[\"options\"])-3} more options')\n",
        "\n",
        "# Compute CCI\n",
        "cci_result = cci_calc.compute(sample['options'])\n",
        "\n",
        "print('\\n' + '='*80)\n",
        "print('CCI ANALYSIS')\n",
        "print('='*80)\n",
        "print(f'CCI Score: {cci_result[\"cci_score\"]:.3f}')\n",
        "print(f'\\nFeature Breakdown:')\n",
        "for feature, value in cci_result['features'].items():\n",
        "    print(f'  {feature}: {value:.3f}')"
      ],
      "metadata": {
        "id": "custom_experiment"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“š Understanding the Framework\n",
        "\n",
        "### Choice Complexity Index (CCI)\n",
        "Measures **external** complexity of the choice problem:\n",
        "- Number of options\n",
        "- Number of attributes per option\n",
        "- Attribute variance (how different options are)\n",
        "- Redundancy (similar options)\n",
        "- Pareto optimality\n",
        "\n",
        "### Internal LLM Decision Complexity (ILDC)\n",
        "Measures **internal** decision difficulty experienced by the LLM:\n",
        "- Volatility: How often the choice changes across samples\n",
        "- Confidence: Average confidence across decisions\n",
        "- Disagreement: Number of unique choices\n",
        "\n",
        "### Controller Strategies\n",
        "- **None**: No intervention\n",
        "- **Naive Top-K**: Always show top 5 options\n",
        "- **CCI-Only**: Prune based on external complexity\n",
        "- **Two-Tier**: Use both CCI and ILDC for adaptive control\n",
        "\n",
        "**Key Insight:** High CCI doesn't always mean high ILDC! The framework adapts based on actual LLM difficulty."
      ],
      "metadata": {
        "id": "framework_docs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ’¾ Download Results\n",
        "\n",
        "Download the generated files to your local machine."
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Create a zip file with all results\n",
        "!zip -r results_colab_demo.zip results/colab_demo/\n",
        "\n",
        "print('Results packaged! Downloading...')\n",
        "files.download('results_colab_demo.zip')\n",
        "print('âœ… Download complete!')"
      ],
      "metadata": {
        "id": "download_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸš€ Next Steps\n",
        "\n",
        "1. **Integrate with Real LLMs**: Modify `src/llm_adapter.py` to use OpenAI/Anthropic APIs\n",
        "2. **Run Full Benchmark**: Use `experiments/run_benchmark.py` with real datasets\n",
        "3. **Customize Controllers**: Modify `src/controller.py` for your use case\n",
        "4. **Add Your Data**: Create custom datasets in `src/datasets.py`\n",
        "\n",
        "### Repository\n",
        "- GitHub: [soroushbagheri/choice-complexity-llm](https://github.com/soroushbagheri/choice-complexity-llm)\n",
        "- Paper: [Coming soon]\n",
        "\n",
        "### Questions?\n",
        "Open an issue on GitHub or contact the authors."
      ],
      "metadata": {
        "id": "next_steps"
      }
    }
  ]
}